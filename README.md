# Video Analysis Agent (Standalone)

This project provides a **standalone analysis agent** for visual verification of test steps using multimodal LLMs (e.g., GPT-4o).

> **Note:** The files `agent_inner_thoughts.json` and `feature_result.html` referenced in this project are expected to be generated by running [testzeus-hercules](https://github.com/your-org/testzeus-hercules) or a compatible test execution framework.

## What is this?

- The `AnalysisAgent` is designed to:
  - Parse planned test steps and test result HTML.
  - Extract frames from a video proof.
  - Use a multimodal LLM to verify if each step is visually observed in the video.
  - Output a deviation report for each step.

## Folder Structure

```
video_analysis_agent/
├── agent/
│   ├── __init__.py
│   ├── core.py              # Main AnalysisAgent class
│   ├── llm/
│   │   ├── __init__.py
│   │   ├── helper.py        # Minimal LLM helper utilities (standalone)
│   │   └── config_manager.py# Minimal config manager (standalone, hardcoded config)
│   └── tools/
│       ├── __init__.py
│       ├── analyze.py       # Tool function for deviation analysis
│       └── registry.py      # Minimal tool decorator (standalone)
├── __init__.py
├── README.md
└── main.py                  # Entry point CLI
```

## Installation

- Requires **Python 3.8+**

### Recommended: Using [uv](https://github.com/astral-sh/uv)

[uv](https://github.com/astral-sh/uv) is a fast, modern Python package manager. To install dependencies with uv:

```bash
uv pip install -r pyproject.toml
```

Or, to create a virtual environment and install:

```bash
uv venv .venv
source .venv/bin/activate
uv pip install -r pyproject.toml
```

### Alternative: Using pip

```bash
pip install autogen opencv-python pillow beautifulsoup4
```

Or use the dependencies listed in `pyproject.toml`.

## Configuration

The agent uses OpenAI's API for multimodal LLMs. You can configure the model and API key via environment variables or by editing `agent/llm/config_manager.py`.

- **Environment variables:**
  - `OPENAI_API_KEY` (required): Your OpenAI API key
  - `OPENAI_MODEL` (optional, default: `gpt-4o`): Model name
  - `OPENAI_BASE_URL` (optional, default: `https://api.openai.com/v1`): API base URL

Example (set in your shell):

```bash
export OPENAI_API_KEY=sk-...yourkey...
export OPENAI_MODEL=gpt-4o
```

## Usage

> **Input files:** The `agent_inner_thoughts.json` and `feature_result.html` files referenced below should be generated by running [testzeus-hercules](https://github.com/test-zeus-ai/testzeus-hercules) or a compatible test execution framework.

### 1. As a Python Library

```python
from agent.core import AnalysisAgent
import asyncio

async def main():
    agent = AnalysisAgent()
    report = await agent.analyze('path/to/agent_inner_thoughts.json', 'path/to/test.feature_result.html')
    print(report)

asyncio.run(main())
```

### 2. Command-Line Interface (CLI)

You can run the agent directly from the command line:

```bash
python main.py --planning_log path/to/agent_inner_thoughts.json --final_output path/to/test.feature_result.html
```

This will print the deviation report to the console.

### 3. As a Tool in Agent Frameworks

The `analyze_test_deviation` function in `agent/tools/analyze.py` can be used as a callable tool:

```python
from agent.tools.analyze import analyze_test_deviation
import asyncio

async def main():
    report = await analyze_test_deviation('path/to/agent_inner_thoughts.json', 'path/to/test.feature_result.html')
    print(report)

asyncio.run(main())
```

## Notes

- This package is **fully standalone** and does not depend on any external codebase.
- To change the LLM or API settings, edit the config in `agent/llm/config_manager.py` or use environment variables.
- For advanced use, you may want to expand the config logic or add CLI wrappers.

---

**Maintainer:** You!
